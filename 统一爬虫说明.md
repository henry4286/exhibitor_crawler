# 统一爬虫程序说明

## 概述

**run_crawler.py** 是整合了单次请求和二次请求两种模式的统一爬虫程序，可根据配置自动选择合适的爬取策略。

## 两种请求模式

### 1. 单次请求模式 (Single Request Mode)

**适用场景**：API直接返回完整的公司信息

**工作流程**：
```
请求分页API → 获取公司列表（含完整信息） → 保存到Excel
```

**特点**：
- ✅ 速度快，只需一次HTTP请求
- ✅ 网络开销小
- ✅ 适合数据结构简单的API

**示例**：无人机展

### 2. 二次请求模式 (Double Request Mode)

**适用场景**：需要先获取公司列表，再逐个获取详细信息或联系人

**工作流程**：
```
请求列表API → 获取公司ID列表 → 
  ↓
并发请求详情API → 获取每个公司的详细信息 → 保存到Excel
```

**特点**：
- ✅ 可获取更详细的信息
- ✅ 支持联系人信息提取
- ✅ 多线程并发获取详情，提高效率
- ⚠️ 网络请求量大，需要注意频率控制

**示例**：农产品展（需要获取联系人信息）

## 配置方法

在 `config.xlsx` 中添加 `request_mode` 列：

| exhibition_code | request_mode | url | url_detail | ... |
|----------------|--------------|-----|------------|-----|
| 无人机展 | single | API地址 | (空) | ... |
| 农产品展 | double | 列表API | 详情API | ... |

### 单次请求模式配置字段

必需字段：
- `exhibition_code`: 展会代码
- `url`: API地址
- `request_method`: 请求方法(GET/POST)
- `headers`: 请求头(JSON)
- `params`: URL参数(JSON)
- `data`: 请求体(JSON)
- `items_key`: 数据列表键路径
- `company_info_keys`: 字段映射(JSON)
- `request_mode`: "single"

### 二次请求模式配置字段

除了上述字段外，还需要：
- `request_mode`: "double"
- `url_detail`: 详情API地址（支持#company_id占位符）
- `request_method_detail`: 详情请求方法
- `headers_detail`: 详情请求头(JSON)
- `params_detail`: 详情URL参数
- `data_detail`: 详情请求体
- `items_key_detail`: 详情数据键路径
- `info_key`: 联系人字段映射(JSON)
- `company_name_key`: 公司名称字段路径
- `id_key`: 公司ID字段路径

**配置示例**：
```json
// 二次请求模式的字段映射
{
  "info_key": {
    "姓名": "name",
    "职位": "position",
    "电话": "phone",
    "邮箱": "email"
  },
  "company_name_key": "companyName",
  "id_key": "id",
  "url_detail": "https://api.example.com/detail/# "
}
```

## 使用方法

### 基本用法

```bash
# 自动根据配置选择模式
python run_crawler.py 无人机展

# 指定线程数
python run_crawler.py 无人机展 --workers 8

# 从指定页开始抓取（断点续传）
python run_crawler.py 无人机展 --start-page 50
```

### 高级用法

```bash
# 二次请求模式（自动识别）
python run_crawler.py 农产品展 --workers 6

# 单次请求模式
python run_crawler.py 无人机展 --workers 4

# 组合使用：指定线程数和起始页
python run_crawler.py 无人机展 --workers 8 --start-page 50
```

### 参数说明

| 参数 | 说明 | 默认值 | 示例 |
|------|------|--------|------|
| `exhibition_code` | 展会代码（必需） | - | `无人机展` |
| `--workers N` | 并发线程数 | 4 | `--workers 8` |
| `--start-page N` | 起始页码 | 1 | `--start-page 50` |

### 断点续传功能 ⭐新增

**使用场景**：当爬虫中途失败或中断时，可以从指定页继续抓取，避免重复下载已获取的数据。

```bash
# 示例：假设在第45页时失败
# 查看已保存的Excel文件确定最后成功的页码
# 然后从下一页继续
python run_crawler.py 无人机展 --start-page 46
```

**注意事项**：
- ✅ 数据会追加到已有的Excel文件中
- ✅ 支持单次请求和二次请求两种模式
- ⚠️ 请确保起始页码准确，避免数据重复或遗漏
- 💡 建议配合 `--workers` 参数提高续传速度

## 程序架构

```
run_crawler.py                 # 统一入口，自动选择模式
├── UnifiedCrawler                 # 统一爬虫类
│   ├── SingleFetchMode → CompanyCrawler (单次请求)
│   └── DoubleFetchMode → DoubleFetchCrawler (二次请求)
│
└── crawler_lib/                   # 模块化组件
    ├── config_manager.py          # 配置管理（支持两种模式）
    ├── http_client.py             # HTTP请求
    ├── data_parser.py             # 数据解析
    ├── excel_exporter.py          # Excel导出
    ├── crawler.py                 # 单次请求爬虫
    ├── detail_fetcher.py          # 详情获取器
    └── utils.py                   # 工具函数
```

**解决方案**：
- 采用动态翻页机制
- 顺序模式：持续爬取直到连续3页无数据
- 并行模式：批量爬取（每批10页）+ 动态扩展


## 输出文件

所有模式的数据都保存到：
```
ExhibitorList/
└── {exhibition_code}.xlsx
```

**单次请求模式输出**：
- 公司信息的所有字段（根据company_info_keys配置）

**二次请求模式输出**：
- `company_name` 列 + 联系人字段（根据info_key配置）
- 每个联系人一行
- 支持一个公司多个联系人

## 运行示例

### 示例1：单次请求（无人机展）

```bash
$ python run_crawler.py 无人机展

============================================================
统一爬虫程序 v3.0
============================================================
展会代码: 无人机展
线程数: 4
============================================================

📋 检测到请求模式: single
✨ 使用单次请求模式（直接获取完整数据）
使用并行爬取模式，线程数: 4

开始爬取第 1-10 页
第1页完成，获取到10条数据
第2页完成，获取到10条数据
...
第84页完成，获取到5条数据
批次完成，最后连续空页数: 6

==================================================
爬取完成！
成功页数: 84
总数据量: 835 条
耗时: 33.63 秒
==================================================
```

### 示例2：二次请求（农产品展）

```bash
$ python run_crawler.py 农产品展 --workers 6

============================================================
统一爬虫程序 v3.0
============================================================
展会代码: 农产品展
线程数: 6
============================================================

📋 检测到请求模式: double
🔄 使用二次请求模式（先获取列表，再获取详情）

📄 正在获取第1页公司列表...
✅ 第1页获取到 20 个公司
📥 开始批量获取 20 个公司的联系人
✅ 批量获取完成，成功: 20, 失败: 0
� 第1页保存 45 条联系人

...

==================================================
爬取完成！
总公司数: 156
总联系人: 342
==================================================
```


## 故障排查

### 问题1：提示"未找到配置"

**原因**：config.xlsx 中不存在该展会代码

**解决**：检查 exhibition_code 拼写是否正确

### 问题2：二次请求模式无数据

**原因**：
1. url_detail 配置错误
2. items_key_detail 路径不正确
3. 占位符 #company_id 未正确替换

**解决**：
- 检查详情API配置
- 验证字段路径
- 测试单个公司ID的详情请求

## 总结

**run_crawler.py** 实现了：

1. ✅ **模式整合**：一个程序支持两种请求模式
2. ✅ **自动识别**：根据配置自动选择合适的模式
4. ✅ **模块复用**：共享基础模块，减少代码冗余
5. ✅ **向后兼容**：不影响现有程序和配置

---

**版本**: v3.0  
**更新日期**: 2025-12-04  
**作者**: 重构优化版
