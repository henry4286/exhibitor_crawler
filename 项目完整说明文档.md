# 数据抓取项目完整说明文档

## 项目概述

这是一个功能完整的企业信息数据抓取项目，支持从不同API接口抓取展会企业信息。项目采用模块化设计，提供了从配置管理到数据抓取的完整解决方案。

### 核心特性

- ✅ **双模式支持**：单次请求模式和二次请求模式
- ✅ **图形化配置**：提供GUI界面编辑配置文件
- ✅ **配置验证**：专门的测试工具验证配置正确性
- ✅ **模块化设计**：可复用的爬虫库组件
- ✅ **断点续传**：支持从中断位置继续抓取
- ✅ **多线程并发**：提高抓取效率
- ✅ **Excel导出**：标准化数据输出格式

## 项目结构

```
项目根目录/
├── 核心程序
│   ├── run_crawler.py          # 统一爬虫入口（推荐使用）
│   ├── simple_crawler.py      # 简化版爬虫
│   └── main.py                 # 图形化配置编辑器
│
├── 工具程序
│   └── test_config.py          # 配置测试工具
│
├── 核心库
│   └── crawler_lib/            # 模块化爬虫库
│       ├── __init__.py
│       ├── config_manager.py   # 配置管理
│       ├── crawler.py          # 爬虫核心类
│       ├── detail_fetcher.py   # 详情获取器
│       ├── http_client.py      # HTTP客户端
│       ├── data_parser.py      # 数据解析器
│       ├── excel_exporter.py   # Excel导出器
│       ├── request_mode.py     # 请求模式处理
│       └── utils.py            # 工具函数
│
├── 配置文件
│   └── config.xlsx             # 展会配置文件
│
├── 扩展模块
│   └── plus/                   # 特定展会扩展
│       ├── 汽配展.py
│       ├── company_detail.py
│       ├── mituan.py
│       └── 汽配展爬虫优化说明.md
│
└── 文档
    ├── 统一爬虫说明.md         # 原有文档（仅介绍run_crawler）
    └── 项目完整说明文档.md     # 本文档（完整项目说明）
```

## 核心程序详解

### 1. 统一爬虫程序 (run_crawler.py) ⭐推荐

**功能**：项目的核心爬虫程序，支持单次和二次请求两种模式

**适用场景**：
- 需要抓取展会企业信息
- 支持批量并发处理
- 需要断点续传功能

**使用方法**：
```bash
# 基本用法
python run_crawler.py <exhibition_code>

# 指定线程数
python run_crawler.py 无人机展 --workers 8

# 断点续传
python run_crawler.py 无人机展 --start-page 50

# 组合使用
python run_crawler.py 无人机展 --workers 8 --start-page 50
```

**支持模式**：
- **单次请求模式**：API直接返回完整企业信息
- **二次请求模式**：先获取企业列表，再获取详细信息

### 2. 简化版爬虫 (simple_crawler.py)

**功能**：轻量级爬虫程序，适用于简单的抓取任务

**特点**：
- 代码结构简洁
- 适合快速测试
- 支持并行和顺序两种模式

**使用方法**：
```bash
# 默认4线程并行
python simple_crawler.py 无人机展

# 指定线程数
python simple_crawler.py 无人机展 8

# 单线程顺序抓取
python simple_crawler.py 无人机展 1 False
```

### 3. 图形化配置编辑器 (main.py)

**功能**：提供用户友好的GUI界面，用于编辑config.xlsx配置文件

**特点**：
- 直观的图形界面
- 支持增删改查操作
- 实时配置验证
- 内置爬虫运行功能

**功能模块**：
- **基本配置页**：展会代码、URL、请求参数等
- **二次请求配置页**：详情API、字段映射等
- **运行配置页**：线程数、起始页、实时日志

**启动方法**：
```bash
python main.py
```

**界面截图描述**：
- 左侧：配置列表，显示所有展会
- 右侧：分页配置界面
  - 基本配置：展会基本信息
  - 二次请求配置：详情请求相关
  - 运行配置：参数设置和运行控制

## 工具程序详解

### 配置测试工具 (test_config.py)

**功能**：在正式抓取前测试配置是否正确，避免浪费时间和资源

**测试内容**：
1. ✅ 配置文件格式验证
2. ✅ API连接测试
3. ✅ 数据提取路径验证
4. ✅ 字段映射测试
5. ✅ 二次请求功能测试（如适用）

**使用方法**：
```bash
python test_config.py <exhibition_code>

# 示例
python test_config.py 无人机展
python test_config.py 农产品展
```

**输出示例**：
```
============================================================
配置测试工具 - 无人机展
============================================================

==================== 基本配置信息 ====================
展会代码: 无人机展
请求模式: single
URL: https://api.example.com/exhibitors

==================== 测试列表API请求 ====================
✅ 请求成功！
响应数据类型: dict
响应字段数: 5
✅ 成功提取数据列表
数据条数: 10

==================== 测试字段映射 ====================
✅ company_name: 无人机科技有限公司
✅ booth_number: A123
⚠️ contact_person: (空)
映射结果: 8/10 个字段有值

==================== 测试总结 ====================
✅ 配置测试完成 - 所有测试通过！
```

## 核心库模块 (crawler_lib/)

### 1. ConfigManager (config_manager.py)
**功能**：统一管理所有爬虫配置
- 从Excel加载配置
- 配置验证和默认值处理
- 支持单次和二次请求两种配置格式

### 2. CompanyCrawler (crawler.py)
**功能**：单次请求模式爬虫实现
- 动态翻页机制
- 并发处理支持
- 自动边界检测

### 3. DoubleFetchCrawler (crawler.py)
**功能**：二次请求模式爬虫实现
- 列表页抓取
- 详情页批量获取
- 联系人信息提取

### 4. DetailFetcher (detail_fetcher.py)
**功能**：详情获取专用模块
- 并发请求详情API
- 错误重试机制
- 数据去重处理

### 5. HttpClient (http_client.py)
**功能**：统一的HTTP请求处理
- 支持GET/POST方法
- 自动处理请求头和参数
- SSL证书验证控制

### 6. DataParser (data_parser.py)
**功能**：数据解析和字段映射
- 嵌套数据路径解析
- 字段映射转换
- 数据类型处理

### 7. ExcelExporter (excel_exporter.py)
**功能**：Excel文件导出
- 标准化输出格式
- 支持数据追加
- 自动样式设置

## 配置文件详解 (config.xlsx)

### 基本配置字段

| 字段名 | 类型 | 必需 | 说明 | 示例 |
|--------|------|------|------|------|
| exhibition_code | 文本 | ✅ | 展会代码 | 无人机展 |
| request_mode | 枚举 | ✅ | 请求模式 | single/double |
| url | URL | ✅ | API地址 | https://api.example.com |
| request_method | 枚举 | ❌ | 请求方法 | GET/POST |
| headers | JSON | ❌ | 请求头 | {"Content-Type": "application/json"} |
| params | JSON | ❌ | URL参数 | {"page": 1, "size": 20} |
| data | JSON | ❌ | 请求体 | {"exhibition": "无人机展"} |
| items_key | 路径 | ❌ | 数据列表路径 | data.items |
| company_info_keys | JSON | ✅ | 字段映射 | {"公司名称": "name", "展位号": "booth"} |

### 二次请求配置字段（request_mode = double时必需）

| 字段名 | 类型 | 必需 | 说明 | 示例 |
|--------|------|------|------|------|
| url_detail | URL | ✅ | 详情API地址 | https://api.example.com/detail/#company_id |
| request_method_detail | 枚举 | ❌ | 详情请求方法 | GET |
| headers_detail | JSON | ❌ | 详情请求头 | {} |
| params_detail | JSON | ❌ | 详情URL参数 | {} |
| data_detail | JSON | ❌ | 详情请求体 | {} |
| items_key_detail | 路径 | ❌ | 详情数据路径 | data.contacts |
| info_key | JSON | ❌ | 联系人字段映射 | {"姓名": "name", "职位": "position"} |
| company_name_key | 路径 | ✅ | 公司名称字段 | companyName |
| id_key | 路径 | ✅ | 公司ID字段 | id |

## 使用流程指南

### 第一次使用

1. **配置测试**
   ```bash
   python test_config.py <展会代码>
   ```

2. **运行爬虫**
   ```bash
   python run_crawler.py <展会代码>
   ```

### 添加新展会配置

#### 方法1：使用图形化编辑器（推荐）
```bash
python main.py
```
在GUI界面中：
1. 点击"新增"
2. 填写配置信息
3. 点击"保存"
4. 使用"运行配置"页面测试

#### 方法2：直接编辑Excel
1. 打开config.xlsx
2. 添加新行，填写配置
3. 运行测试验证

### 调试配置问题

1. **测试配置**：
   ```bash
   python test_config.py <展会代码>
   ```

2. **查看详细错误**：
   检查errorlog.txt文件

3. **使用图形化界面**：
   运行main.py查看实时日志

## 高级功能

### 断点续传

当爬虫中途失败时，可以从指定页继续：

```bash
# 假设在第50页失败
python run_crawler.py 无人机展 --start-page 51
```

### 性能优化

1. **调整线程数**：
   ```bash
   # 增加线程数（注意不要过高）
   python run_crawler.py 无人机展 --workers 8
   ```

2. **单线程调试**：
   ```bash
   python run_crawler.py 无人机展 --workers 1
   ```

### 批量处理

可以编写批处理脚本处理多个展会：

```bash
#!/bin/bash
exhibitions=("无人机展" "农产品展" "汽配展")

for expo in "${exhibitions[@]}"; do
    echo "开始处理: $expo"
    python run_crawler.py "$expo"
done
```

## 输出文件说明

### 数据文件位置
```
ExhibitorList/
└── <exhibition_code>.xlsx
```

### 文件格式
- **单次请求模式**：每行一个企业，包含所有配置字段
- **二次请求模式**：每行一个联系人，包含企业信息和联系人详情

### 字段说明
根据`company_info_keys`和`info_key`配置决定具体字段

## 故障排查

### 常见问题

#### 1. 配置不存在
```
错误: 未找到展会 'xxx' 的配置
```
**解决**：
- 检查展会代码拼写
- 确认config.xlsx中存在该配置

#### 2. API连接失败
```
错误: 请求失败: 404 Not Found
```
**解决**：
- 检查URL配置
- 验证网络连接
- 测试API可用性

#### 3. 数据提取失败
```
未能提取到数据列表
```
**解决**：
- 检查items_key配置
- 使用test_config.py测试
- 查看API响应格式

#### 4. 字段映射为空
```
⚠️ 有5个字段映射为空
```
**解决**：
- 检查字段路径是否正确
- 验证API响应中的字段名
- 使用test_config.py查看实际数据结构

### 调试技巧

1. **使用测试工具**：
   ```bash
   python test_config.py <展会代码>
   ```

2. **查看详细日志**：
   检查errorlog.txt和python_excute_status.txt

3. **单线程调试**：
   ```bash
   python run_crawler.py <展会代码> --workers 1
   ```

4. **图形化界面监控**：
   ```bash
   python main.py
   ```

## 最佳实践

### 1. 配置管理
- 使用图形化编辑器管理配置
- 每次修改后运行测试验证
- 保持配置文件备份

### 2. 运行监控
- 先用test_config.py测试
- 从小线程数开始，逐步增加
- 监控错误日志

### 3. 数据质量
- 定期检查输出数据
- 验证字段映射准确性
- 关注数据完整性

### 4. 性能优化
- 根据API限制调整线程数
- 使用断点续传避免重复抓取
- 合理设置超时时间

## 版本信息

- **当前版本**：v3.1
- **最后更新**：2025-12-04
- **Python要求**：3.7+
- **主要依赖**：pandas, openpyxl, requests, urllib3, tkinter

## 联系支持

如遇到问题：
1. 首先查看本文档的故障排查部分
2. 使用test_config.py进行配置测试
3. 检查错误日志文件
4. 如仍未解决，可提供详细的错误信息和配置内容

---

**文档版本**：v1.0  
**更新日期**：2025-12-04  
**适用范围**：完整项目功能说明
