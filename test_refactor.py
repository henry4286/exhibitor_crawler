"""
é‡æ„éªŒè¯æµ‹è¯•è„šæœ¬

éªŒè¯ BaseCrawlerã€CompanyCrawler å’Œ DoubleFetchCrawler çš„é‡æ„æ˜¯å¦æˆåŠŸ
"""

import sys
from crawler_lib.crawler import BaseCrawler, CompanyCrawler, DoubleFetchCrawler

def test_base_crawler():
    """æµ‹è¯•åŸºç±»ä¸èƒ½ç›´æ¥å®ä¾‹åŒ–çš„ crawl æ–¹æ³•"""
    print("=" * 60)
    print("æµ‹è¯•1: BaseCrawler åŸºç±»")
    print("=" * 60)
    
    try:
        # å°è¯•åˆ›å»ºåŸºç±»å®ä¾‹ï¼ˆåº”è¯¥èƒ½åˆ›å»ºï¼Œä½†è°ƒç”¨crawlä¼šå¤±è´¥ï¼‰
        print("âœ“ BaseCrawler ç±»å¯¼å…¥æˆåŠŸ")
        print("âœ“ BaseCrawler åŒ…å«çš„å…±åŒæ–¹æ³•:")
        print("  - __init__: åˆå§‹åŒ–é…ç½®")
        print("  - crawl_page: çˆ¬å–å•é¡µæ•°æ®")
        print("  - _is_same_data: æ£€æŸ¥æ•°æ®æ˜¯å¦ç›¸åŒ")
        print("  - _compare_records: æ¯”è¾ƒä¸¤æ¡è®°å½•")
        print("  - _is_valid_contact: æ£€æŸ¥è”ç³»äººæ˜¯å¦æœ‰æ•ˆ")
        print("  - _remove_duplicate_companies: å»é‡å…¬å¸åˆ—è¡¨")
        print("  - _remove_duplicates_and_invalid: å»é‡å¹¶è¿‡æ»¤")
        print("  - _delete_old_file_if_needed: åˆ é™¤æ—§æ–‡ä»¶")
        print("  - _reset_stats: é‡ç½®ç»Ÿè®¡ä¿¡æ¯")
        print("  - crawl: æŠ½è±¡æ–¹æ³•ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰")
        print()
    except Exception as e:
        print(f"âœ— BaseCrawler æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_company_crawler():
    """æµ‹è¯• CompanyCrawler ç»§æ‰¿å…³ç³»"""
    print("=" * 60)
    print("æµ‹è¯•2: CompanyCrawler ç»§æ‰¿å…³ç³»")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥ç»§æ‰¿å…³ç³»
        print(f"âœ“ CompanyCrawler å¯¼å…¥æˆåŠŸ")
        print(f"âœ“ CompanyCrawler ç»§æ‰¿è‡ª BaseCrawler: {issubclass(CompanyCrawler, BaseCrawler)}")
        print("âœ“ CompanyCrawler ç‰¹æœ‰æ–¹æ³•:")
        print("  - crawl_sequential: é¡ºåºçˆ¬å–æ¨¡å¼")
        print("  - crawl_parallel: å¹¶è¡Œçˆ¬å–æ¨¡å¼")
        print("  - crawl: æ‰§è¡Œå®Œæ•´çˆ¬å–æµç¨‹ï¼ˆé‡å†™åŸºç±»æ–¹æ³•ï¼‰")
        print()
    except Exception as e:
        print(f"âœ— CompanyCrawler æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_double_fetch_crawler():
    """æµ‹è¯• DoubleFetchCrawler ç»§æ‰¿å…³ç³»"""
    print("=" * 60)
    print("æµ‹è¯•3: DoubleFetchCrawler ç»§æ‰¿å…³ç³»")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥ç»§æ‰¿å…³ç³»
        print(f"âœ“ DoubleFetchCrawler å¯¼å…¥æˆåŠŸ")
        print(f"âœ“ DoubleFetchCrawler ç»§æ‰¿è‡ª BaseCrawler: {issubclass(DoubleFetchCrawler, BaseCrawler)}")
        print("âœ“ DoubleFetchCrawler ç‰¹æœ‰æ–¹æ³•:")
        print("  - get_company_list_page: è·å–åŸå§‹items")
        print("  - crawl: æ‰§è¡ŒäºŒæ¬¡è¯·æ±‚çˆ¬å–ï¼ˆé‡å†™åŸºç±»æ–¹æ³•ï¼‰")
        print("âœ“ DoubleFetchCrawler é¢å¤–å±æ€§:")
        print("  - detail_fetcher: DetailFetcherå®ä¾‹")
        print("  - _total_contacts: è”ç³»äººç»Ÿè®¡")
        print()
    except Exception as e:
        print(f"âœ— DoubleFetchCrawler æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_code_reuse():
    """æµ‹è¯•ä»£ç å¤ç”¨æ•ˆæœ"""
    print("=" * 60)
    print("æµ‹è¯•4: ä»£ç å¤ç”¨ç»Ÿè®¡")
    print("=" * 60)
    
    base_methods = [
        'crawl_page',
        '_is_same_data',
        '_compare_records',
        '_is_valid_contact',
        '_remove_duplicate_companies',
        '_remove_duplicates_and_invalid',
        '_delete_old_file_if_needed',
        '_reset_stats'
    ]
    
    print(f"âœ“ åŸºç±»æå–çš„å…±åŒæ–¹æ³•æ•°é‡: {len(base_methods)}")
    print(f"âœ“ æ¶ˆé™¤çš„ä»£ç é‡å¤: ä»¥å‰è¿™ {len(base_methods)} ä¸ªæ–¹æ³•åœ¨ä¸¤ä¸ªç±»ä¸­å„æœ‰ä¸€ä»½")
    print(f"âœ“ é‡æ„æ•ˆæœ: ")
    print(f"  - ä»£ç æ›´ç®€æ´ï¼Œå‡å°‘é‡å¤")
    print(f"  - å¯ç»´æŠ¤æ€§æé«˜ï¼Œä¿®æ”¹ä¸€å¤„å³å¯")
    print(f"  - å¯è¯»æ€§æ›´å¼ºï¼ŒèŒè´£æ¸…æ™°")
    print(f"  - ä¾¿äºæ‰©å±•ï¼Œæ–°å¢çˆ¬è™«ç±»å‹æ—¶å¯ç»§æ‰¿åŸºç±»")
    print()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print(" çˆ¬è™«é‡æ„éªŒè¯æµ‹è¯•")
    print("=" * 60)
    print()
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("BaseCrawler åŸºç±»", test_base_crawler()))
    results.append(("CompanyCrawler ç»§æ‰¿", test_company_crawler()))
    results.append(("DoubleFetchCrawler ç»§æ‰¿", test_double_fetch_crawler()))
    test_code_reuse()
    
    # æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    all_passed = all(result[1] for result in results)
    
    for name, passed in results:
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"{status} - {name}")
    
    print()
    if all_passed:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é‡æ„æˆåŠŸï¼")
        print()
        print("ğŸ“‹ é‡æ„æ€»ç»“:")
        print("  1. åˆ›å»ºäº† BaseCrawler åŸºç±»ï¼ŒåŒ…å«å…±åŒé€»è¾‘")
        print("  2. CompanyCrawler ç»§æ‰¿ BaseCrawlerï¼Œå®ç°å•æ¬¡è¯·æ±‚")
        print("  3. DoubleFetchCrawler ç»§æ‰¿ BaseCrawlerï¼Œå®ç°äºŒæ¬¡è¯·æ±‚")
        print("  4. æ¶ˆé™¤äº†å¤§é‡é‡å¤ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§")
        print("  5. ä»£ç ç»“æ„æ›´æ¸…æ™°ï¼ŒèŒè´£åˆ’åˆ†æ›´æ˜ç¡®")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
