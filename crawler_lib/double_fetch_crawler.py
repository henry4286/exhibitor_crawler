"""
äºŒæ¬¡è¯·æ±‚çˆ¬è™«æ¨¡å—

é€‚ç”¨äºéœ€è¦å…ˆè·å–åˆ—è¡¨ï¼Œå†è·å–è¯¦æƒ…çš„åœºæ™¯
"""

from .base_crawler import BaseCrawler
from unified_logger import log_error, log_list_progress, log_contacts_saved, console


class DoubleFetchCrawler(BaseCrawler):
    """
    äºŒæ¬¡è¯·æ±‚çˆ¬è™«ï¼ˆé€é¡µå¤„ç†ç‰ˆï¼‰
    
    é€‚ç”¨äºéœ€è¦å…ˆè·å–åˆ—è¡¨ï¼Œå†è·å–è¯¦æƒ…çš„åœºæ™¯ã€‚
    
    å·¥ä½œæµç¨‹ï¼š
    1. è·å–ä¸€é¡µå…¬å¸åˆ—è¡¨
    2. ç«‹å³æŠ“å–è¿™é¡µæ‰€æœ‰å…¬å¸çš„è”ç³»äºº
    3. ä¿å­˜è¿™ä¸€é¡µçš„è”ç³»äººæ•°æ®åˆ°Excel
    4. ç»§ç»­ä¸‹ä¸€é¡µ
    
    """
    
    def __init__(self, exhibition_code: str, max_workers: int = 4, start_page: int = 1):
        """
        åˆå§‹åŒ–äºŒæ¬¡è¯·æ±‚çˆ¬è™«
        
        Args:
            exhibition_code: å±•ä¼šä»£ç 
            max_workers: æœ€å¤§çº¿ç¨‹æ•°
            start_page: èµ·å§‹é¡µç 
        """
        super().__init__(exhibition_code, max_workers, start_page)
        
        # ä½¿ç”¨DetailFetcheræ¥è·å–è”ç³»äºº
        # æ³¨æ„ï¼šæ­¤æ—¶ self.config å·²ç»åœ¨çˆ¶ç±»åˆå§‹åŒ–æ—¶éªŒè¯è¿‡ï¼Œä¸ä¼šä¸º None
        from .detail_fetcher import DetailFetcher
        if self.config is None:
            raise ValueError("é…ç½®ä¸èƒ½ä¸ºç©º")
        self.detail_fetcher = DetailFetcher(self.config, max_workers=self.max_workers)
        
        # äºŒæ¬¡è¯·æ±‚æ¨¡å¼çš„é¢å¤–ç»Ÿè®¡
        self._total_contacts = 0
    
    def _print_double_summary(self):
        """
        æ‰“å°äºŒæ¬¡è¯·æ±‚çˆ¬å–æ±‡æ€»ä¿¡æ¯
        """
        console("\n" + "="*60)
        console("ğŸ“Š çˆ¬å–æ±‡æ€»")
        console("="*60)
        console(f"å±•ä¼šä»£ç : {self.exhibition_code}")
        console(f"æ€»é¡µæ•°: {self._total_pages}")
        console(f"æ€»å…¬å¸æ•°: {self._total_companies}")
        console(f"æ€»è”ç³»äººæ•°: {self._total_contacts}")
        console("="*60 + "\n")
    
    def crawl(self) -> bool:
        """
        æ‰§è¡Œçˆ¬å–æµç¨‹ï¼ˆäºŒæ¬¡è¯·æ±‚æ¨¡å¼ - é€é¡µå¤„ç†ï¼‰
        
        æ¯è·å–ä¸€é¡µå…¬å¸åˆ—è¡¨ï¼Œå°±ç«‹å³æŠ“å–è”ç³»äººå¹¶ä¿å­˜ï¼Œé¿å…æ•°æ®ä¸¢å¤±ã€‚
        
        Returns:
            æ˜¯å¦æˆåŠŸè·å–åˆ°æ•°æ®
        """

        # ç¡®å®šè¡¨å¤´ - åŸºæœ¬é…ç½®çš„å­—æ®µæ˜ å°„ + è”ç³»äººå­—æ®µæ˜ å°„
        if self.config is None:
            raise ValueError("é…ç½®ä¸èƒ½ä¸ºç©º")
        
        if self.config.info_key:
            headers = list(self.config.company_info_keys.keys()) + list(self.config.info_key.keys())
        else:
            headers = list(self.config.company_info_keys.keys())

        # å›è°ƒï¼šé€é¡µå¤„ç†ï¼ˆæŠ“å–è”ç³»äººå¹¶ä¿å­˜ï¼‰
        def _process_page(page: int, items: list):
            log_list_progress(page, len(items))

            # æŠ“å–è”ç³»äºº
            all_contacts = self.detail_fetcher.fetch_batch_contacts_with_basic_info(
                companies_basic_info=items
            )

            if all_contacts:
                try:
                    self.exporter.save(all_contacts, self.exhibition_code, headers)
                    self._total_contacts += len(all_contacts)
                    log_contacts_saved(page, len(all_contacts))
                except Exception as e:
                    log_error(f"ä¿å­˜ç¬¬{page}é¡µè”ç³»äººæ•°æ®å¤±è´¥", e)

            # æ›´æ–°å…¬å¸æ•°ç»Ÿè®¡ï¼ˆä¿æŒåŸè¡Œä¸ºï¼‰
            self._total_companies += len(items)
            self._total_pages += 1

            # ç»§ç»­åˆ†é¡µé»˜è®¤
            return True

        try:
            # åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœä»ç¬¬ä¸€é¡µå¼€å§‹ï¼‰
            self._delete_old_file_if_needed()
            
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self._reset_stats()

            has_data = self.paginate_sequential(
                start_page=self.start_page,
                process_page_callback=_process_page
            )
            
            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            if has_data:
                self._print_double_summary()

            return has_data

        except KeyboardInterrupt:
            log_error("ç”¨æˆ·ä¸­æ–­ï¼Œå·²ä¿å­˜çš„æ•°æ®ä¸ä¼šä¸¢å¤±")
        except Exception as e:
            log_error("çˆ¬å–è¿‡ç¨‹å‡ºé”™", e)

        return False
