"""
å¤šçº¿ç¨‹ç‰ˆæœ¬çš„å…¬å¸è¯¦æƒ…çˆ¬è™«ç¨‹åº
é€šè¿‡é…ç½®æ–‡ä»¶é©±åŠ¨çš„ä¸¤æ¬¡è¯·æ±‚çˆ¬è™«ï¼Œè·å–å…¬å¸åŠè”ç³»äººä¿¡æ¯
æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘å¤„ç†ï¼Œæé«˜æ•°æ®æŠ“å–é€Ÿåº¦
æ”¯æŒæ™ºèƒ½é‡è¯•æœºåˆ¶ï¼Œå¤„ç†HTTPé”™è¯¯å’Œä¸šåŠ¡å±‚é¢çš„å¤±è´¥
"""

import json
import os
import sys
import time
import random
import threading
import multiprocessing
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Any, Optional, Union, Tuple, Callable
from abc import ABC, abstractmethod
from queue import Queue
from dataclasses import dataclass, field
from enum import Enum
import urllib3

import pandas as pd
import requests
from requests.adapters import HTTPAdapter
from urllib.parse import urlencode

import save_to_excel

# å…¨å±€è°ƒè¯•æ¨¡å¼æ§åˆ¶
DEBUG_MODE = False


class RetryError(Exception):
    """é‡è¯•å¤±è´¥å¼‚å¸¸"""
    def __init__(self, message: str, last_response: Any = None, attempts: int = 0):
        super().__init__(message)
        self.last_response = last_response
        self.attempts = attempts


@dataclass
class RetryConfig:
    """é‡è¯•é…ç½®æ•°æ®ç±»
    
    Attributes:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼Œå•ä½ç§’ï¼ˆé»˜è®¤1ç§’ï¼‰
        max_delay: æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼Œå•ä½ç§’ï¼ˆé»˜è®¤60ç§’ï¼‰
        exponential_base: æŒ‡æ•°é€€é¿çš„åŸºæ•°ï¼ˆé»˜è®¤2ï¼‰
        jitter: æ˜¯å¦æ·»åŠ éšæœºæŠ–åŠ¨ï¼ˆé»˜è®¤Trueï¼Œé¿å…æƒŠç¾¤æ•ˆåº”ï¼‰
        retry_on_http_errors: éœ€è¦é‡è¯•çš„HTTPçŠ¶æ€ç åˆ—è¡¨
        retry_on_exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹åˆ—è¡¨
    """
    max_retries: int = 5
    base_delay: float = 1.0
    max_delay: float = 60.0
    exponential_base: float = 2.0
    jitter: bool = True
    retry_on_http_errors: List[int] = field(default_factory=lambda: [429, 500, 502, 503, 504])
    retry_on_exceptions: List[type] = field(default_factory=lambda: [
        requests.exceptions.Timeout,
        requests.exceptions.ConnectionError,
        requests.exceptions.ChunkedEncodingError,
    ])
    
    def calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—ç¬¬Næ¬¡é‡è¯•çš„å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ + å¯é€‰æŠ–åŠ¨ï¼‰"""
        delay = min(
            self.base_delay * (self.exponential_base ** attempt),
            self.max_delay
        )
        if self.jitter:
            # æ·»åŠ Â±25%çš„éšæœºæŠ–åŠ¨
            jitter_range = delay * 0.25
            delay = delay + random.uniform(-jitter_range, jitter_range)
        return max(0, delay)


class ResponseValidator:
    """å“åº”éªŒè¯å™¨ - ç”¨äºåˆ¤æ–­APIå“åº”æ˜¯å¦è¡¨ç¤ºæˆåŠŸ
    
    æ”¯æŒå¤šç§éªŒè¯è§„åˆ™ï¼Œå¯é€šè¿‡é…ç½®æ–‡ä»¶åŠ¨æ€æŒ‡å®šï¼š
    1. å­—æ®µå€¼æ£€æŸ¥ï¼šæ£€æŸ¥å“åº”ä¸­ç‰¹å®šå­—æ®µæ˜¯å¦ç­‰äº/ä¸ç­‰äºæŸä¸ªå€¼
    2. å­—æ®µå­˜åœ¨æ£€æŸ¥ï¼šæ£€æŸ¥å“åº”ä¸­æ˜¯å¦å­˜åœ¨ç‰¹å®šå­—æ®µ
    3. å…³é”®è¯æ£€æŸ¥ï¼šæ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å¤±è´¥ç›¸å…³çš„å…³é”®è¯
    4. è‡ªå®šä¹‰éªŒè¯å‡½æ•°
    
    é…ç½®æ ¼å¼ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰:
    {
        "success_field": "success",           # æˆåŠŸæ ‡å¿—å­—æ®µè·¯å¾„
        "success_value": true,                # æˆåŠŸæ—¶çš„å€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºtrueï¼‰
        "code_field": "code",                 # çŠ¶æ€ç å­—æ®µè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        "success_codes": [0, 200, 1],         # æˆåŠŸçš„çŠ¶æ€ç åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        "failure_keywords": ["é¢‘ç¹", "ç¨å", "é™åˆ¶", "å¤±è´¥"],  # å¤±è´¥å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        "data_field": "data"                  # æ•°æ®å­—æ®µè·¯å¾„ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®ï¼ˆå¯é€‰ï¼‰
    }
    """
    
    # é€šç”¨å¤±è´¥å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
    DEFAULT_FAILURE_KEYWORDS = [
        # ä¸­æ–‡å…³é”®è¯
        "è¯·æ±‚è¿‡äºé¢‘ç¹", "ç¨åå†è¯•", "è¯·ç¨å", "æ“ä½œé¢‘ç¹", "è®¿é—®è¿‡å¿«",
        "è¯·æ±‚é™åˆ¶", "è®¿é—®é™åˆ¶", "é¢‘ç‡é™åˆ¶", "é™æµ", "è¢«é™åˆ¶",
        "æœåŠ¡å™¨ç¹å¿™", "ç³»ç»Ÿç¹å¿™", "æœåŠ¡ç¹å¿™", "è¯·æ±‚å¤±è´¥", "æ“ä½œå¤±è´¥",
        "tokenå¤±æ•ˆ", "tokenè¿‡æœŸ", "ç™»å½•å¤±æ•ˆ", "ä¼šè¯è¿‡æœŸ", "æœªæˆæƒ",
        "å‚æ•°é”™è¯¯", "å‚æ•°æ— æ•ˆ", "éæ³•è¯·æ±‚", "è¯·æ±‚æ— æ•ˆ",
        # è‹±æ–‡å…³é”®è¯
        "rate limit", "too many requests", "try again later", "please wait",
        "request failed", "server busy", "service unavailable",
        "token expired", "unauthorized", "invalid token",
        "invalid request", "bad request"
    ]
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            config: éªŒè¯é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤çš„é€šç”¨éªŒè¯è§„åˆ™
        """
        self.config = config or {}
        self.success_field = self.config.get('success_field')
        self.success_value = self.config.get('success_value', True)
        self.code_field = self.config.get('code_field')
        self.success_codes = self.config.get('success_codes', [0, 200, 1, "0", "200", "1"])
        self.failure_keywords = self.config.get('failure_keywords', self.DEFAULT_FAILURE_KEYWORDS)
        self.data_field = self.config.get('data_field')
        self.message_field = self.config.get('message_field', 'message')
    
    def validate(self, response: Any) -> Tuple[bool, str]:
        """éªŒè¯å“åº”æ˜¯å¦æˆåŠŸ
        
        Args:
            response: APIå“åº”æ•°æ®ï¼ˆé€šå¸¸æ˜¯å­—å…¸ï¼‰
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, å¤±è´¥åŸå› æè¿°)
        """
        if response is None:
            return False, "å“åº”ä¸ºç©º"
        
        # å¦‚æœå“åº”ä¸æ˜¯å­—å…¸ï¼Œå°è¯•è¿›è¡ŒåŸºæœ¬éªŒè¯
        if not isinstance(response, dict):
            if isinstance(response, list):
                # åˆ—è¡¨å“åº”é€šå¸¸è¡¨ç¤ºæˆåŠŸ
                return True, ""
            return False, f"å“åº”æ ¼å¼å¼‚å¸¸: {type(response)}"
        
        # 1. æ£€æŸ¥æˆåŠŸæ ‡å¿—å­—æ®µ
        if self.success_field:
            success_value = self._get_nested_value(response, self.success_field)
            if success_value is not None:
                # å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„å¸ƒå°”å€¼
                if isinstance(success_value, str):
                    success_value = success_value.lower() in ('true', '1', 'yes', 'ok')
                if success_value != self.success_value:
                    msg = self._get_nested_value(response, self.message_field) or "ä¸šåŠ¡å¤„ç†å¤±è´¥"
                    return False, f"ä¸šåŠ¡å¤±è´¥: {msg}"
        
        # 2. æ£€æŸ¥çŠ¶æ€ç å­—æ®µ
        if self.code_field:
            code_value = self._get_nested_value(response, self.code_field)
            if code_value is not None:
                # è½¬æ¢ä¸ºå¯æ¯”è¾ƒçš„æ ¼å¼
                code_str = str(code_value)
                success_codes_str = [str(c) for c in self.success_codes]
                if code_str not in success_codes_str:
                    msg = self._get_nested_value(response, self.message_field) or f"çŠ¶æ€ç å¼‚å¸¸: {code_value}"
                    return False, f"çŠ¶æ€ç é”™è¯¯({code_value}): {msg}"
        
        # 3. æ£€æŸ¥å¤±è´¥å…³é”®è¯
        response_str = json.dumps(response, ensure_ascii=False).lower()
        for keyword in self.failure_keywords:
            if keyword.lower() in response_str:
                msg = self._get_nested_value(response, self.message_field) or f"æ£€æµ‹åˆ°å¤±è´¥å…³é”®è¯: {keyword}"
                return False, f"å…³é”®è¯åŒ¹é…: {msg}"
        
        # 4. æ£€æŸ¥æ•°æ®å­—æ®µæ˜¯å¦å­˜åœ¨ä¸”éç©ºï¼ˆå¯é€‰ï¼‰
        if self.data_field:
            data_value = self._get_nested_value(response, self.data_field)
            if data_value is None or (isinstance(data_value, (list, dict, str)) and len(data_value) == 0):
                # æ•°æ®ä¸ºç©ºä¸ä¸€å®šæ˜¯é”™è¯¯ï¼Œå¯èƒ½åªæ˜¯æ²¡æœ‰æ•°æ®ï¼Œè¿™é‡Œåªè®°å½•ä½†ä¸åˆ¤æ–­ä¸ºå¤±è´¥
                debug_print(f"æ•°æ®å­—æ®µ '{self.data_field}' ä¸ºç©º")
        
        return True, ""
    
    def _get_nested_value(self, data: Dict[str, Any], key_path: str) -> Any:
        """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼"""
        if not key_path:
            return None
        
        keys = key_path.split('.')
        current = data
        
        try:
            for key in keys:
                if isinstance(current, dict):
                    current = current.get(key)
                elif isinstance(current, list):
                    try:
                        current = current[int(key)]
                    except (ValueError, IndexError):
                        return None
                else:
                    return None
                if current is None:
                    return None
            return current
        except Exception:
            return None
    
    @classmethod
    def from_config_string(cls, config_str: Optional[str]) -> 'ResponseValidator':
        """ä»é…ç½®å­—ç¬¦ä¸²åˆ›å»ºéªŒè¯å™¨"""
        if not config_str or pd.isna(config_str) or config_str == '':
            return cls()
        
        try:
            if isinstance(config_str, str):
                config = json.loads(config_str)
            elif isinstance(config_str, dict):
                config = config_str
            else:
                config = {}
            return cls(config)
        except (json.JSONDecodeError, TypeError):
            return cls()

def debug_print(message: str, force_flush: bool = True):
    """è°ƒè¯•ä¿¡æ¯æ‰“å°å‡½æ•°ï¼Œåªåœ¨DEBUG_MODEä¸ºTrueæ—¶è¾“å‡º"""
    if DEBUG_MODE:
        print(f"[{threading.current_thread().name}] {message}", flush=force_flush)


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ï¼Œè´Ÿè´£è¯»å–å’Œè§£æExcelé…ç½®æ–‡ä»¶"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = None
    
    def load_config(self, exhibition_code: str) -> Dict[str, Any]:
        """åŠ è½½æŒ‡å®šå±•è§ˆçš„é…ç½®"""
        try:
            df = pd.read_excel(self.config_path)
            config_row = df[df['exhibition_code'] == exhibition_code]
            
            if config_row.empty:
                raise ValueError(f"No configuration found for exhibition_code: {exhibition_code}")
            
            self.config = config_row.iloc[0].to_dict()
            return self.config
            
        except Exception as e:
            raise RuntimeError(f"Failed to load config: {e}")
    
    def get_company_list_config(self) -> Dict[str, Any]:
        """è·å–å…¬å¸åˆ—è¡¨è¯·æ±‚é…ç½®"""
        if not self.config:
            raise ValueError("Config not loaded")
        
        return {
            'url': self.config.get('url'),
            'method': self.config.get('request_method', 'GET'),
            'headers': self._safe_json_load(self.config.get('headers') or '{}'),
            'params': self._safe_json_load(self.config.get('params') or '{}'),
            'data': self._safe_json_load(self.config.get('data') or '{}'),
            'paging_key': self.config.get('pagging'),
            'items_key': self.config.get('items_key'),
            'company_name_key': self.config.get('company_name_key'),
            'id_key': self.config.get('id_key')
        }
    
    def get_company_detail_config(self) -> Dict[str, Any]:
        """è·å–å…¬å¸è¯¦æƒ…è¯·æ±‚é…ç½®"""
        if not self.config:
            raise ValueError("Config not loaded")
        
        return {
            'url': self.config.get('url_detail'),
            'method': self.config.get('request_method_detail'),
            'headers': self._safe_json_load(self.config.get('headers_detail') or '{}'),
            'params': self._safe_json_load(self.config.get('params_detail') or '{}'),
            'data': self._safe_json_load(self.config.get('data_detail') or '{}'),
            'items_key': self.config.get('items_key_detail'),
            'info_key': self._safe_json_load(self.config.get('info_key') or '{}')
        }
    
    def get_retry_config(self) -> RetryConfig:
        """è·å–é‡è¯•é…ç½®
        
        ä»Excelé…ç½®ä¸­è¯»å–é‡è¯•ç›¸å…³å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        æ”¯æŒçš„é…ç½®å­—æ®µï¼š
        - retry_max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        - retry_base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        - retry_max_delay: æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        """
        if not self.config:
            return RetryConfig()
        
        return RetryConfig(
            max_retries=int(self.config.get('retry_max_retries', 3)),
            base_delay=float(self.config.get('retry_base_delay', 1.0)),
            max_delay=float(self.config.get('retry_max_delay', 60.0)),
            exponential_base=float(self.config.get('retry_exponential_base', 2.0)),
            jitter=bool(self.config.get('retry_jitter', True))
        )
    
    def get_response_validator(self) -> ResponseValidator:
        """è·å–å“åº”éªŒè¯å™¨é…ç½®
        
        ä»Excelé…ç½®ä¸­è¯»å–éªŒè¯å™¨å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤éªŒè¯å™¨
        æ”¯æŒçš„é…ç½®å­—æ®µï¼ˆJSONæ ¼å¼ï¼‰ï¼š
        - response_validator: å“åº”éªŒè¯é…ç½®JSONå­—ç¬¦ä¸²
        """
        if not self.config:
            return ResponseValidator()
        
        validator_config = self.config.get('response_validator')
        return ResponseValidator.from_config_string(validator_config)
    
    def _safe_json_load(self, json_str: Any) -> Dict[str, Any]:
        """å®‰å…¨åœ°åŠ è½½JSONå­—ç¬¦ä¸²"""
        try:
            if pd.isna(json_str) or json_str == '' or json_str is None:
                return {}
            if isinstance(json_str, str):
                return json.loads(json_str)
            elif isinstance(json_str, dict):
                return json_str
            else:
                return {}
        except (json.JSONDecodeError, TypeError):
            return {}


class ThreadSafeHTTPClient:
    """çº¿ç¨‹å®‰å…¨çš„HTTPå®¢æˆ·ç«¯ï¼Œè´Ÿè´£å‘é€è¯·æ±‚
    
    æ”¯æŒæ™ºèƒ½é‡è¯•æœºåˆ¶ï¼š
    1. HTTPå±‚é¢çš„é”™è¯¯é‡è¯•ï¼ˆç½‘ç»œé”™è¯¯ã€è¶…æ—¶ã€æœåŠ¡å™¨é”™è¯¯ç­‰ï¼‰
    2. ä¸šåŠ¡å±‚é¢çš„é”™è¯¯é‡è¯•ï¼ˆé€šè¿‡ResponseValidatoréªŒè¯å“åº”å†…å®¹ï¼‰
    3. æŒ‡æ•°é€€é¿ç­–ç•¥ï¼Œé¿å…å¯¹æœåŠ¡å™¨é€ æˆå‹åŠ›
    """
    
    def __init__(self, retry_config: Optional[RetryConfig] = None, 
                 response_validator: Optional[ResponseValidator] = None):
        """åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        
        Args:
            retry_config: é‡è¯•é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            response_validator: å“åº”éªŒè¯å™¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤éªŒè¯å™¨
        """
        # ç¦ç”¨SSLè­¦å‘Š
        urllib3.disable_warnings()
        # åˆ›å»ºsessionä¼šè¯æ± ï¼Œæé«˜è¿æ¥å¤ç”¨ç‡
        self._session_lock = threading.Lock()
        self._sessions = {}
        # é‡è¯•é…ç½®
        self.retry_config = retry_config or RetryConfig()
        # å“åº”éªŒè¯å™¨
        self.response_validator = response_validator or ResponseValidator()
        # é‡è¯•ç»Ÿè®¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._stats_lock = threading.Lock()
        self._retry_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_retries': 0,
            'http_errors': 0,
            'business_errors': 0
        }
    
    def _get_session(self, thread_id: str) -> requests.Session:
        """è·å–çº¿ç¨‹ä¸“ç”¨çš„session"""
        with self._session_lock:
            if thread_id not in self._sessions:
                self._sessions[thread_id] = requests.Session()
                # é…ç½®session - æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨HTTPAdapterçš„max_retries
                # å› ä¸ºæˆ‘ä»¬å®ç°äº†è‡ªå·±çš„é‡è¯•é€»è¾‘ï¼Œå¯ä»¥å¤„ç†ä¸šåŠ¡å±‚é¢çš„å¤±è´¥
                adapter = HTTPAdapter(
                    pool_connections=10,
                    pool_maxsize=20,
                    max_retries=0  # ç¦ç”¨Adapterå±‚çš„é‡è¯•ï¼Œä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„é‡è¯•é€»è¾‘
                )
                self._sessions[thread_id].mount('http://', adapter)
                self._sessions[thread_id].mount('https://', adapter)
            return self._sessions[thread_id]
    
    def _execute_request(self, session: requests.Session, url: str, method: str,
                        headers: Optional[Dict[str, Any]] = None,
                        params: Optional[Dict[str, Any]] = None,
                        data: Optional[Dict[str, Any]] = None) -> requests.Response:
        """æ‰§è¡Œå•æ¬¡HTTPè¯·æ±‚ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        request_params = {
            'headers': headers or {},
            'verify': False,
            'timeout': 30
        }
        
        if method.upper() == 'GET':
            if params:
                request_params['params'] = params
            return session.get(url, **request_params)
            
        elif method.upper() == 'POST':
            if params:
                request_params['params'] = urlencode(params)
            if data:
                if headers and "Content-Type" in headers and "urlencoded" in headers["Content-Type"]:
                    request_params['data'] = urlencode(data)
                else:
                    request_params['data'] = json.dumps(data)
            return session.post(url, **request_params)
            
        else:
            raise ValueError(f"Unsupported request method: {method}")
    
    def send_request(self, url: str, method: str, headers: Optional[Dict[str, Any]] = None,
                    params: Optional[Dict[str, Any]] = None, data: Optional[Dict[str, Any]] = None,
                    retry_config: Optional[RetryConfig] = None,
                    response_validator: Optional[ResponseValidator] = None) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            url: è¯·æ±‚URL
            method: è¯·æ±‚æ–¹æ³•ï¼ˆGET/POSTï¼‰
            headers: è¯·æ±‚å¤´
            params: URLå‚æ•°
            data: è¯·æ±‚ä½“æ•°æ®
            retry_config: æœ¬æ¬¡è¯·æ±‚çš„é‡è¯•é…ç½®ï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰
            response_validator: æœ¬æ¬¡è¯·æ±‚çš„å“åº”éªŒè¯å™¨ï¼ˆè¦†ç›–é»˜è®¤éªŒè¯å™¨ï¼‰
            
        Returns:
            è§£æåçš„JSONå“åº”æ•°æ®
            
        Raises:
            RetryError: é‡è¯•æ¬¡æ•°ç”¨å°½åä»ç„¶å¤±è´¥
            ValueError: ä¸æ”¯æŒçš„è¯·æ±‚æ–¹æ³•
        """
        thread_id = threading.current_thread().name
        session = self._get_session(thread_id)
        
        # ä½¿ç”¨æœ¬æ¬¡è¯·æ±‚çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        config = retry_config or self.retry_config
        validator = response_validator or self.response_validator
        
        # æ›´æ–°ç»Ÿè®¡
        with self._stats_lock:
            self._retry_stats['total_requests'] += 1
        
        last_exception = None
        last_response = None
        
        for attempt in range(config.max_retries + 1):
            try:
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
                if attempt > 0:
                    delay = config.calculate_delay(attempt - 1)
                    debug_print(f"ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{delay:.2f}ç§’...")
                    print(f"â³ [{thread_id}] ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{delay:.2f}ç§’åé‡æ–°è¯·æ±‚...", flush=True)
                    time.sleep(delay)
                    
                    with self._stats_lock:
                        self._retry_stats['total_retries'] += 1
                
                # æ‰§è¡Œè¯·æ±‚
                response = self._execute_request(session, url, method, headers, params, data)
                
                # æ£€æŸ¥HTTPçŠ¶æ€ç 
                if response.status_code in config.retry_on_http_errors:
                    with self._stats_lock:
                        self._retry_stats['http_errors'] += 1
                    raise requests.exceptions.HTTPError(
                        f"HTTP {response.status_code}: æœåŠ¡å™¨è¿”å›é”™è¯¯çŠ¶æ€ç ",
                        response=response
                    )
                
                # å°è¯•è§£æå“åº”
                try:
                    response_data = json.loads(response.content)
                except json.JSONDecodeError as e:
                    debug_print(f"JSONè§£æå¤±è´¥: {e}")
                    # å¦‚æœå“åº”ä¸æ˜¯JSONï¼Œæ£€æŸ¥HTTPçŠ¶æ€ç 
                    response.raise_for_status()
                    # å¦‚æœçŠ¶æ€ç æ­£å¸¸ä½†ä¸æ˜¯JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                    return {"_raw_response": response.text}
                
                last_response = response_data
                
                # ä½¿ç”¨éªŒè¯å™¨æ£€æŸ¥ä¸šåŠ¡å±‚é¢çš„æˆåŠŸ/å¤±è´¥
                is_success, error_msg = validator.validate(response_data)
                
                if is_success:
                    # è¯·æ±‚æˆåŠŸ
                    with self._stats_lock:
                        self._retry_stats['successful_requests'] += 1
                    
                    if attempt > 0:
                        print(f"âœ… [{thread_id}] ç¬¬{attempt}æ¬¡é‡è¯•æˆåŠŸï¼", flush=True)
                    
                    return response_data
                else:
                    # ä¸šåŠ¡å±‚é¢çš„å¤±è´¥ï¼Œéœ€è¦é‡è¯•
                    with self._stats_lock:
                        self._retry_stats['business_errors'] += 1
                    
                    debug_print(f"ä¸šåŠ¡éªŒè¯å¤±è´¥: {error_msg}")
                    
                    if attempt < config.max_retries:
                        print(f"âš ï¸  [{thread_id}] è¯·æ±‚å¤±è´¥ï¼ˆ{error_msg}ï¼‰ï¼Œå‡†å¤‡é‡è¯•...", flush=True)
                    
                    # ç»§ç»­é‡è¯•å¾ªç¯
                    last_exception = RetryError(error_msg, last_response, attempt + 1)
                    continue
                    
            except (requests.exceptions.Timeout, 
                    requests.exceptions.ConnectionError, 
                    requests.exceptions.ChunkedEncodingError) as e:
                # å¯é‡è¯•çš„ç½‘ç»œå¼‚å¸¸
                last_exception = e
                with self._stats_lock:
                    self._retry_stats['http_errors'] += 1
                
                debug_print(f"è¯·æ±‚å¼‚å¸¸ (attempt {attempt + 1}): {type(e).__name__}: {e}")
                
                if attempt < config.max_retries:
                    print(f"âš ï¸  [{thread_id}] è¯·æ±‚å¼‚å¸¸ï¼ˆ{type(e).__name__}ï¼‰ï¼Œå‡†å¤‡é‡è¯•...", flush=True)
                continue
                
            except requests.exceptions.HTTPError as e:
                # HTTPé”™è¯¯
                last_exception = e
                with self._stats_lock:
                    self._retry_stats['http_errors'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„çŠ¶æ€ç 
                if hasattr(e, 'response') and e.response is not None:
                    if e.response.status_code in config.retry_on_http_errors:
                        debug_print(f"HTTPé”™è¯¯ {e.response.status_code}ï¼Œå‡†å¤‡é‡è¯•...")
                        if attempt < config.max_retries:
                            print(f"âš ï¸  [{thread_id}] HTTPé”™è¯¯ï¼ˆ{e.response.status_code}ï¼‰ï¼Œå‡†å¤‡é‡è¯•...", flush=True)
                        continue
                
                # ä¸å¯é‡è¯•çš„HTTPé”™è¯¯
                raise
                
            except Exception as e:
                # å…¶ä»–ä¸å¯é‡è¯•çš„å¼‚å¸¸
                debug_print(f"ä¸å¯é‡è¯•çš„å¼‚å¸¸: {type(e).__name__}: {e}")
                raise
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        with self._stats_lock:
            self._retry_stats['failed_requests'] += 1
        
        error_msg = f"è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯•{config.max_retries}æ¬¡"
        if last_exception:
            error_msg += f"ï¼Œæœ€åä¸€æ¬¡é”™è¯¯: {last_exception}"
        
        print(f"âŒ [{thread_id}] {error_msg}", flush=True)
        
        # å¦‚æœæœ‰æœ€åçš„å“åº”æ•°æ®ï¼ŒæŠ›å‡ºåŒ…å«å“åº”çš„å¼‚å¸¸
        if last_response is not None:
            raise RetryError(error_msg, last_response, config.max_retries + 1)
        elif last_exception:
            raise RetryError(error_msg, None, config.max_retries + 1) from last_exception
        else:
            raise RetryError(error_msg, None, config.max_retries + 1)
    
    def send_request_no_retry(self, url: str, method: str, headers: Optional[Dict[str, Any]] = None,
                             params: Optional[Dict[str, Any]] = None, 
                             data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆä¸å¸¦é‡è¯•ï¼Œç”¨äºå…¼å®¹æ—§ä»£ç ï¼‰"""
        thread_id = threading.current_thread().name
        session = self._get_session(thread_id)
        
        response = self._execute_request(session, url, method, headers, params, data)
        response.raise_for_status()
        return json.loads(response.content)
    
    def get_retry_stats(self) -> Dict[str, int]:
        """è·å–é‡è¯•ç»Ÿè®¡ä¿¡æ¯"""
        with self._stats_lock:
            return self._retry_stats.copy()
    
    def reset_retry_stats(self):
        """é‡ç½®é‡è¯•ç»Ÿè®¡"""
        with self._stats_lock:
            self._retry_stats = {
                'total_requests': 0,
                'successful_requests': 0,
                'failed_requests': 0,
                'total_retries': 0,
                'http_errors': 0,
                'business_errors': 0
            }
    
    def print_retry_stats(self):
        """æ‰“å°é‡è¯•ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_retry_stats()
        print("\nğŸ“Š è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯:", flush=True)
        print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}", flush=True)
        print(f"   æˆåŠŸè¯·æ±‚: {stats['successful_requests']}", flush=True)
        print(f"   å¤±è´¥è¯·æ±‚: {stats['failed_requests']}", flush=True)
        print(f"   é‡è¯•æ¬¡æ•°: {stats['total_retries']}", flush=True)
        print(f"   HTTPé”™è¯¯: {stats['http_errors']}", flush=True)
        print(f"   ä¸šåŠ¡é”™è¯¯: {stats['business_errors']}", flush=True)
        
        if stats['total_requests'] > 0:
            success_rate = stats['successful_requests'] / stats['total_requests'] * 100
            print(f"   æˆåŠŸç‡: {success_rate:.1f}%", flush=True)


class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ï¼Œè´Ÿè´£è§£æå’Œè½¬æ¢æ•°æ®"""
    
    @staticmethod
    def get_nested_value(data: Dict[str, Any], key_path: str) -> Any:
        """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼ï¼Œæ”¯æŒç‚¹å·åˆ†éš”çš„è·¯å¾„"""
        if not key_path or pd.isna(key_path):
            return ""
        
        keys = key_path.split('.')
        current = data
        
        try:
            for i, key in enumerate(keys):
                debug_print(f"è°ƒè¯•ä¿¡æ¯ - å¤„ç†é”® {i}: '{key}', å½“å‰ç±»å‹: {type(current)}")
                if isinstance(current, dict):
                    if key not in current:
                        debug_print(f"è°ƒè¯•ä¿¡æ¯ - é”® '{key}' ä¸å­˜åœ¨äºå­—å…¸ä¸­")
                        return ""
                    current = current[key]
                elif isinstance(current, list):
                    try:
                        key_index = int(key)
                        if key_index < len(current):
                            current = current[key_index]
                        else:
                            debug_print(f"è°ƒè¯•ä¿¡æ¯ - ç´¢å¼• {key_index} è¶…å‡ºåˆ—è¡¨èŒƒå›´ {len(current)}")
                            return ""
                    except ValueError:
                        debug_print(f"è°ƒè¯•ä¿¡æ¯ - æ— æ³•å°†é”® '{key}' è½¬æ¢ä¸ºæ•´æ•°")
                        return ""
                else:
                    debug_print(f"è°ƒè¯•ä¿¡æ¯ - å½“å‰å€¼ä¸æ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼Œç±»å‹: {type(current)}")
                    return ""
                debug_print(f"è°ƒè¯•ä¿¡æ¯ - å¤„ç†åå½“å‰å€¼: {type(current)}")
            return current
        except (KeyError, IndexError, ValueError, TypeError) as e:
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - get_nested_valueé”™è¯¯: {e}, key_path: {key_path}, current_type: {type(current)}")
            return ""
    
    @staticmethod
    def update_nested_value(data: Dict[str, Any], key_path: str, value: Any) -> Dict[str, Any]:
        """æ›´æ–°åµŒå¥—å­—å…¸ä¸­çš„å€¼"""
        if not isinstance(data, dict):
            raise ValueError("Input should be a dictionary")
        
        keys = key_path.split('.')
        current = data
        
        for key in keys[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
        return data
    
    @staticmethod
    def extract_contact_info(company_data: Dict[str, Any], contact_data: Union[Dict, List],
                           company_name_key: str, info_key: Dict[str, str]) -> List[Dict[str, Any]]:
        """æå–è”ç³»äººä¿¡æ¯"""
        contacts = []
        
        # è·å–å…¬å¸åŸºç¡€ä¿¡æ¯
        company_name = DataProcessor.get_nested_value(company_data, company_name_key) or "æœªçŸ¥å…¬å¸"
        
        # å¤„ç†å…¬å¸å­—æ®µæ˜ å°„ï¼ˆæ’é™¤å…¬å¸åç§°å­—æ®µï¼Œé¿å…é‡å¤ï¼‰
        company_fields = company_name_key.split(',') if company_name_key else []
        # è·å–ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºå…¬å¸åç§°å­—æ®µï¼ˆé€šå¸¸company_name_keyå°±æ˜¯å…¬å¸åç§°çš„è·¯å¾„ï¼‰
        primary_company_field = company_fields[0].strip() if company_fields else None
        
        if isinstance(contact_data, dict):
            # å•ä¸ªè”ç³»äºº
            contact_info = {"company_name": company_name}
            
            # æ·»åŠ é¢å¤–çš„å…¬å¸ä¿¡æ¯å­—æ®µï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»ä½œä¸ºcompany_nameæ·»åŠ ï¼‰
            for field in company_fields[1:]:
                field = field.strip()
                if field:
                    contact_info[field] = DataProcessor.get_nested_value(company_data, field)
            
            # æ˜ å°„è”ç³»äººå­—æ®µ
            for output_key, input_key in info_key.items():
                contact_info[output_key] = DataProcessor.get_nested_value(contact_data, input_key)
            
            contacts.append(contact_info)
            
        elif isinstance(contact_data, list):
            # å¤šä¸ªè”ç³»äºº
            for contact in contact_data:
                contact_info = {"company_name": company_name}
                
                # æ·»åŠ é¢å¤–çš„å…¬å¸ä¿¡æ¯å­—æ®µï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»ä½œä¸ºcompany_nameæ·»åŠ ï¼‰
                for field in company_fields[1:]:
                    field = field.strip()
                    if field:
                        contact_info[field] = company_data.get(field, "")
                
                # æ˜ å°„è”ç³»äººå­—æ®µ
                for output_key, input_key in info_key.items():
                    contact_info[output_key] = DataProcessor.get_nested_value(contact, input_key)
                
                contacts.append(contact_info)
                
        else:
            # æ²¡æœ‰è”ç³»äººæ•°æ®ï¼Œåªä¿å­˜å…¬å¸ä¿¡æ¯
            contact_info = {"company_name": company_name}
            
            # æ·»åŠ é¢å¤–çš„å…¬å¸ä¿¡æ¯å­—æ®µï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»ä½œä¸ºcompany_nameæ·»åŠ ï¼‰
            for field in company_fields[1:]:
                field = field.strip()
                if field:
                    contact_info[field] = company_data.get(field, "")
            
            # ç©ºçš„è”ç³»äººå­—æ®µ
            for output_key in info_key.keys():
                contact_info[output_key] = ""
            
            contacts.append(contact_info)
        
        return contacts


class ThreadSafeProgressManager:
    """çº¿ç¨‹å®‰å…¨çš„è¿›åº¦ç®¡ç†å™¨ï¼Œè´Ÿè´£æ–­ç‚¹ç»­ä¼ åŠŸèƒ½"""
    
    def __init__(self, exhibition_code: str):
        self.exhibition_code = exhibition_code
        # ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        temp_dir = os.path.join(script_dir, 'temp')
        # ç¡®ä¿tempç›®å½•å­˜åœ¨
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)
        self.progress_file = os.path.join(temp_dir, f"progress_{exhibition_code}.json")
        self.saved_companies_file = os.path.join(temp_dir, f"saved_companies_{exhibition_code}.txt")
        self._file_lock = threading.Lock()
        self._memory_lock = threading.Lock()
    
    def load_progress(self) -> Dict[str, Any]:
        """åŠ è½½è¿›åº¦"""
        try:
            if os.path.exists(self.progress_file):
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥ï¼š{e}", flush=True)
        
        return {
            'page_index': 1,
            'contact_counter': 0,
            'processed_companies_count': 0
        }
    
    def load_saved_companies(self) -> set:
        """åŠ è½½å·²å¤„ç†çš„å…¬å¸IDé›†åˆ"""
        try:
            if os.path.exists(self.saved_companies_file):
                with open(self.saved_companies_file, 'r', encoding='utf-8') as f:
                    return set(line.strip() for line in f if line.strip())
        except Exception as e:
            print(f"åŠ è½½å·²å¤„ç†å…¬å¸åˆ—è¡¨å¤±è´¥ï¼š{e}", flush=True)
        
        return set()
    
    def save_progress(self, page_index: int, contact_counter: int, processed_count: int):
        """ä¿å­˜è¿›åº¦"""
        try:
            with self._file_lock:
                progress_data = {
                    'page_index': page_index,
                    'contact_counter': contact_counter,
                    'processed_companies_count': processed_count,
                    'last_update': time.strftime('%Y-%m-%d %H:%M:%S')
                }
                
                with open(self.progress_file, 'w', encoding='utf-8') as f:
                    json.dump(progress_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜è¿›åº¦å¤±è´¥ï¼š{e}", flush=True)
    
    def save_company_id(self, company_id: str):
        """ä¿å­˜å·²å¤„ç†çš„å…¬å¸ID"""
        try:
            with self._file_lock:
                with open(self.saved_companies_file, 'a', encoding='utf-8') as f:
                    f.write(f"{company_id}\n")
        except Exception as e:
            print(f"ä¿å­˜å…¬å¸IDå¤±è´¥ï¼š{e}", flush=True)
    
    def is_company_processed(self, company_id: str, saved_companies: set) -> bool:
        """æ£€æŸ¥å…¬å¸æ˜¯å¦å·²å¤„ç†"""
        return str(company_id) in saved_companies
    
    def reset_progress(self):
        """é‡ç½®è¿›åº¦æ–‡ä»¶"""
        try:
            with self._file_lock:
                if os.path.exists(self.progress_file):
                    os.remove(self.progress_file)
                    print(f"ğŸ—‘ï¸  å·²åˆ é™¤è¿›åº¦æ–‡ä»¶ï¼š{self.progress_file}")
        except Exception as e:
            print(f"åˆ é™¤è¿›åº¦æ–‡ä»¶å¤±è´¥ï¼š{e}", flush=True)
        
        try:
            with self._file_lock:
                if os.path.exists(self.saved_companies_file):
                    os.remove(self.saved_companies_file)
                    print(f"ğŸ—‘ï¸  å·²åˆ é™¤å…¬å¸åˆ—è¡¨æ–‡ä»¶ï¼š{self.saved_companies_file}")
        except Exception as e:
            print(f"åˆ é™¤å…¬å¸åˆ—è¡¨æ–‡ä»¶å¤±è´¥ï¼š{e}", flush=True)


class ThreadSafeDataSaver:
    """çº¿ç¨‹å®‰å…¨çš„æ•°æ®ä¿å­˜å™¨"""
    
    def __init__(self, exhibition_code: str, batch_size: int = 50):
        self.exhibition_code = exhibition_code
        self.batch_size = batch_size
        self._data_queue = Queue()
        self._save_lock = threading.Lock()
        self._contact_counter = 0
        self._total_saved = 0
    
    def add_contacts(self, contacts: List[Dict[str, Any]]):
        """æ·»åŠ è”ç³»äººæ•°æ®åˆ°é˜Ÿåˆ—"""
        with self._save_lock:
            self._data_queue.put(contacts)
            self._contact_counter += len(contacts)
    
    def save_batch(self) -> int:
        """ä¿å­˜å½“å‰æ‰¹æ¬¡çš„æ•°æ®"""
        contacts_to_save = []
        
        # ä»é˜Ÿåˆ—ä¸­å–å‡ºæ•°æ®
        while not self._data_queue.empty() and len(contacts_to_save) < self.batch_size:
            try:
                contacts = self._data_queue.get_nowait()
                contacts_to_save.extend(contacts)
            except:
                break
        
        if contacts_to_save:
            try:
                save_to_excel.save(contacts_to_save, self.exhibition_code)
                with self._save_lock:
                    self._total_saved += len(contacts_to_save)
                    saved_count = len(contacts_to_save)
                    print(f"ğŸ’¾ çº¿ç¨‹å®‰å…¨ä¿å­˜æ‰¹æ¬¡ï¼š{saved_count}ä¸ªè”ç³»äººï¼ˆæ€»è®¡ï¼š{self._total_saved}ä¸ªï¼‰", flush=True)
                    return saved_count
            except Exception as e:
                print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥ï¼š{e}", flush=True)
                return 0
        
        return 0
    
    def get_contact_count(self) -> int:
        """è·å–å·²å¤„ç†çš„è”ç³»äººæ€»æ•°"""
        with self._save_lock:
            return self._contact_counter
    
    def get_total_saved(self) -> int:
        """è·å–å·²ä¿å­˜çš„è”ç³»äººæ€»æ•°"""
        with self._save_lock:
            return self._total_saved
    
    def force_save_all(self):
        """å¼ºåˆ¶ä¿å­˜æ‰€æœ‰å‰©ä½™æ•°æ®"""
        while not self._data_queue.empty():
            self.save_batch()


class MultiThreadedDataCrawler:
    """å¤šçº¿ç¨‹æ•°æ®çˆ¬è™«ç±»
    
    æ”¯æŒæ™ºèƒ½é‡è¯•æœºåˆ¶çš„å¤šçº¿ç¨‹æ•°æ®çˆ¬è™«ï¼Œå¯å¤„ç†ï¼š
    1. HTTPå±‚é¢çš„é”™è¯¯ï¼ˆç½‘ç»œè¶…æ—¶ã€è¿æ¥é”™è¯¯ç­‰ï¼‰
    2. ä¸šåŠ¡å±‚é¢çš„é”™è¯¯ï¼ˆå¦‚"è¯·æ±‚è¿‡äºé¢‘ç¹"ç­‰ï¼‰
    3. è‡ªåŠ¨é‡è¯•å¹¶ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
    """
    
    def __init__(self, exhibition_code: str, config_path: str, 
                 page_workers: Optional[int] = None, company_workers: Optional[int] = None):
        self.exhibition_code = exhibition_code
        self.config_manager = ConfigManager(config_path)
        
        # åŠ è½½é…ç½®ï¼ˆéœ€è¦å…ˆåŠ è½½é…ç½®æ‰èƒ½è·å–é‡è¯•é…ç½®ï¼‰
        self.config = self.config_manager.load_config(exhibition_code)
        self.company_list_config = self.config_manager.get_company_list_config()
        self.company_detail_config = self.config_manager.get_company_detail_config()
        
        # è·å–é‡è¯•é…ç½®å’Œå“åº”éªŒè¯å™¨
        self.retry_config = self.config_manager.get_retry_config()
        self.response_validator = self.config_manager.get_response_validator()
        
        # åˆ›å»ºå¸¦æœ‰é‡è¯•é…ç½®çš„HTTPå®¢æˆ·ç«¯
        self.http_client = ThreadSafeHTTPClient(
            retry_config=self.retry_config,
            response_validator=self.response_validator
        )
        
        self.data_processor = DataProcessor()
        self.progress_manager = ThreadSafeProgressManager(exhibition_code)
        self.data_saver = ThreadSafeDataSaver(exhibition_code)
        
        # è·å–CPUæ ¸å¿ƒæ•°å¹¶æ™ºèƒ½è®¾ç½®é»˜è®¤çº¿ç¨‹æ•°
        cpu_count = multiprocessing.cpu_count()
        
        # å¤šçº¿ç¨‹é…ç½® - åŸºäºCPUæ ¸å¿ƒæ•°æ™ºèƒ½è®¾ç½®
        if page_workers is None:
            # é¡µé¢è·å–çº¿ç¨‹ï¼šI/Oå¯†é›†å‹ï¼Œå¯ä»¥å¤šä¸€äº›ï¼Œä½†ä¸è¶…è¿‡4ä¸ª
            self.page_workers = min(cpu_count, 4)
        else:
            self.page_workers = page_workers
            
        if company_workers is None:
            # å…¬å¸å¤„ç†çº¿ç¨‹ï¼šæ¯é¡µ10-20æ¡å…¬å¸ï¼Œæ•°æ®é‡ä¸å¤§ï¼Œä¸è¶…è¿‡CPUæ ¸å¿ƒæ•°
            self.company_workers = min(cpu_count, 6)
        else:
            self.company_workers = company_workers
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.wait_time = random.uniform(0.1, 0.3)  # é™ä½é¡µé¢é—´å»¶è¿Ÿ
        self.contact_counter = 0
        self.processed_count = 0
        
        # æ‰“å°é‡è¯•é…ç½®ä¿¡æ¯
        print(f"ğŸ”„ é‡è¯•é…ç½®ï¼šæœ€å¤§é‡è¯•æ¬¡æ•°={self.retry_config.max_retries}, "
              f"åŸºç¡€å»¶è¿Ÿ={self.retry_config.base_delay}ç§’, "
              f"æœ€å¤§å»¶è¿Ÿ={self.retry_config.max_delay}ç§’", flush=True)
    
    def get_companies_page(self, page_index: int) -> Optional[List[Dict[str, Any]]]:
        """è·å–æŒ‡å®šé¡µçš„å…¬å¸åˆ—è¡¨"""
        try:
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            params = self.company_list_config['params'].copy()
            data = self.company_list_config['data'].copy()
            
            # è°ƒè¯•ä¿¡æ¯
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - é¡µç : {page_index}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - åŸå§‹params: {params}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - åŸå§‹data: {data}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - åˆ†é¡µé”®: {self.company_list_config['paging_key']}")
            
            # å¤„ç†åˆ†é¡µ
            paging_key = self.company_list_config['paging_key']
            if paging_key and page_index is not None and not pd.isna(paging_key):
                # ä¿æŒåŸå§‹å‚æ•°ç±»å‹ï¼Œé¿å…ç±»å‹è½¬æ¢é—®é¢˜
                page_value = str(page_index)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if params:
                    params = self.data_processor.update_nested_value(params, paging_key, page_value)
                if data:
                    data = self.data_processor.update_nested_value(data, paging_key, page_value)
            
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - å¤„ç†åparams: {params}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - å¤„ç†ådata: {data}")
            
            # å‘é€è¯·æ±‚
            response = self.http_client.send_request(
                url=self.company_list_config['url'],
                method=self.company_list_config['method'],
                headers=self.company_list_config['headers'],
                params=params,
                data=data
            )
            
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - å“åº”ç±»å‹: {type(response)}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - å“åº”keys: {list(response.keys()) if isinstance(response, dict) else 'Not a dict'}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - response['returnObj']: {response.get('returnObj')}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - response['returnObj']ç±»å‹: {type(response.get('returnObj'))}")
            if response.get('returnObj'):
                debug_print(f"è°ƒè¯•ä¿¡æ¯ - returnObj keys: {list(response['returnObj'].keys()) if isinstance(response['returnObj'], dict) else 'Not a dict'}")
            
            # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„æ•°æ®å­—æ®µ
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - response['pager']: {response.get('pager')}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - response['isSuccess']: {response.get('isSuccess')}")
            debug_print("è°ƒè¯•ä¿¡æ¯ - å®Œæ•´å“åº”å†…å®¹:")
            debug_print(json.dumps(response, ensure_ascii=False, indent=2))
            
            # æå–å…¬å¸åˆ—è¡¨
            items_key = self.company_list_config['items_key']
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - items_key: {items_key}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - items_keyç±»å‹: {type(items_key)}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - pd.isna(items_key): {pd.isna(items_key)}")
            
            if pd.isna(items_key) or items_key == '':
                companies = response if isinstance(response, list) else [response]
            else:
                companies = self.data_processor.get_nested_value(response, items_key)
            
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - æå–çš„å…¬å¸åˆ—è¡¨ç±»å‹: {type(companies)}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - æå–çš„å…¬å¸åˆ—è¡¨å†…å®¹: {str(companies)[:200] if companies else 'None'}")
            debug_print(f"è°ƒè¯•ä¿¡æ¯ - æå–çš„å…¬å¸åˆ—è¡¨é•¿åº¦: {len(companies) if isinstance(companies, list) else 'Not a list'}")
            
            return companies
                
        except Exception as e:
            print(f"è·å–ç¬¬{page_index}é¡µå…¬å¸åˆ—è¡¨å¤±è´¥ï¼š{e}", flush=True)
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}", flush=True)
            return None
    
    def get_company_contacts(self, company_id: str) -> Optional[Union[Dict, List]]:
        """è·å–æŒ‡å®šå…¬å¸çš„è”ç³»äººä¿¡æ¯"""
        try:
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            params = self.company_detail_config['params'].copy()
            data = self.company_detail_config['data'].copy()
            url = self.company_detail_config['url']
            
            # æ›¿æ¢å…¬å¸IDå ä½ç¬¦
            if params:
                params = {k: (v if v != '#company_id' else company_id) for k, v in params.items()}
            if data:
                data = {k: (v if v != '#company_id' else company_id) for k, v in data.items()}
            url = url.replace("#company_id", str(company_id))
            
            # å‘é€è¯·æ±‚
            response = self.http_client.send_request(
                url=url,
                method=self.company_detail_config['method'],
                headers=self.company_detail_config['headers'],
                params=params,
                data=data
            )
            
            # æå–è”ç³»äººæ•°æ®
            items_key = self.company_detail_config['items_key']
            if not pd.isna(items_key) and items_key and items_key != "{}":
                return self.data_processor.get_nested_value(response, items_key)
            else:
                return response
                
        except Exception as e:
            print(f"è·å–å…¬å¸{company_id}è”ç³»äººä¿¡æ¯å¤±è´¥ï¼š{e}", flush=True)
            return None
    
    def process_company(self, company: Dict[str, Any], saved_companies: set) -> bool:
        """å¤„ç†å•ä¸ªå…¬å¸ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            # è·å–å…¬å¸ä¿¡æ¯
            company_id = self.data_processor.get_nested_value(company, self.company_list_config['id_key'])
            
            if not company_id:
                debug_print(f"å…¬å¸æ²¡æœ‰IDï¼Œè·³è¿‡")
                return False
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if self.progress_manager.is_company_processed(company_id, saved_companies):
                company_name = self.data_processor.get_nested_value(
                    company, self.company_list_config['company_name_key']
                ) or "æœªçŸ¥å…¬å¸"
                debug_print(f"â­ï¸  è·³è¿‡å·²å¤„ç†çš„å…¬å¸ï¼š{company_name}")
                return True
            
            # è·å–å…¬å¸åç§°
            company_name = self.data_processor.get_nested_value(
                company, self.company_list_config['company_name_key']
            ) or "æœªçŸ¥å…¬å¸"
            
            debug_print(f"æ­£åœ¨è·å–{company_name}çš„è”ç³»äººä¿¡æ¯")
            
            # è·å–è”ç³»äººä¿¡æ¯
            contacts = self.get_company_contacts(company_id)
            
            # æå–è”ç³»äººæ•°æ®
            contact_list = self.data_processor.extract_contact_info(
                company_data=company,
                contact_data=contacts if contacts is not None else {},
                company_name_key=self.company_list_config['company_name_key'],
                info_key=self.company_detail_config['info_key']
            )
            
            # æ·»åŠ åˆ°çº¿ç¨‹å®‰å…¨çš„ä¿å­˜å™¨
            if contact_list:
                self.data_saver.add_contacts(contact_list)
            
            # ä¿å­˜å·²å¤„ç†çš„å…¬å¸ID
            self.progress_manager.save_company_id(company_id)
            
            return True
            
        except Exception as e:
            company_name = self.data_processor.get_nested_value(
                company, self.company_list_config['company_name_key']
            ) or "æœªçŸ¥å…¬å¸"
            print(f"å¤„ç†å…¬å¸{company_name}å¤±è´¥ï¼š{e}", flush=True)
            return False
    
    def process_companies_batch(self, companies: List[Dict[str, Any]], saved_companies: set) -> Tuple[int, int]:
        """æ‰¹é‡å¤„ç†å…¬å¸ï¼ˆå¤šçº¿ç¨‹ï¼‰"""
        success_count = 0
        
        with ThreadPoolExecutor(max_workers=self.company_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_company = {
                executor.submit(self.process_company, company, saved_companies): company 
                for company in companies
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(future_to_company):
                try:
                    if future.result():
                        success_count += 1
                except Exception as e:
                    company = future_to_company[future]
                    company_name = self.data_processor.get_nested_value(
                        company, self.company_list_config['company_name_key']
                    ) or "æœªçŸ¥å…¬å¸"
                    print(f"å¤„ç†å…¬å¸{company_name}æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{e}", flush=True)
        
        return success_count, len(companies)
    
    def get_companies_page_concurrent(self, start_page: int, max_pages: int = 5) -> List[Dict[str, Any]]:
        """å¹¶å‘è·å–å¤šé¡µå…¬å¸åˆ—è¡¨"""
        all_companies = []
        
        with ThreadPoolExecutor(max_workers=self.page_workers) as executor:
            # æäº¤é¡µé¢è·å–ä»»åŠ¡
            future_to_page = {
                executor.submit(self.get_companies_page, start_page + i): start_page + i 
                for i in range(min(self.page_workers, max_pages))
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_page):
                page_num = future_to_page[future]
                try:
                    companies = future.result()
                    if companies:
                        all_companies.extend(companies)
                        print(f"ğŸ“„ å¹¶å‘è·å–ç¬¬{page_num}é¡µï¼Œ{len(companies)}æ¡è®°å½•", flush=True)
                    else:
                        print(f"âš ï¸  ç¬¬{page_num}é¡µæ— æ•°æ®", flush=True)
                except Exception as e:
                    print(f"âŒ è·å–ç¬¬{page_num}é¡µå¤±è´¥ï¼š{e}", flush=True)
        
        return all_companies
    
    def run(self):
        """è¿è¡Œå¤šçº¿ç¨‹çˆ¬è™«ä¸»ç¨‹åº"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†å±•è§ˆï¼š{self.exhibition_code}ï¼ˆå¤šçº¿ç¨‹æ¨¡å¼ï¼‰", flush=True)
        
        # è®¡ç®—å®é™…æ€»çº¿ç¨‹æ•°
        actual_total_threads = self.page_workers + self.company_workers + 1  # +1 for background saver
        print(f"âš™ï¸  çº¿ç¨‹é…ç½®ï¼šé¡µé¢è·å–çº¿ç¨‹={self.page_workers}ï¼Œå…¬å¸å¤„ç†çº¿ç¨‹={self.company_workers}ï¼Œå®é™…æ€»çº¿ç¨‹æ•°={actual_total_threads}", flush=True)
        
        # åŠ è½½è¿›åº¦
        progress_data = self.progress_manager.load_progress()
        saved_companies = self.progress_manager.load_saved_companies()
        
        start_page = progress_data.get('page_index', 1)
        self.contact_counter = progress_data.get('contact_counter', 0)
        self.processed_count = progress_data.get('processed_companies_count', 0)
        
        print(f"ğŸ“‹ åŠ è½½è¿›åº¦ï¼šä»ç¬¬{start_page}é¡µå¼€å§‹ï¼Œå·²å¤„ç†{self.processed_count}ä¸ªå…¬å¸ï¼Œå·²è·å–{self.contact_counter}ä¸ªè”ç³»äºº", flush=True)
        
        # å¯åŠ¨åå°ä¿å­˜çº¿ç¨‹
        def background_saver():
            while True:
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦ä¿å­˜
                if self.data_saver.save_batch() > 0:
                    debug_print("åå°ä¿å­˜çº¿ç¨‹å·²ä¿å­˜æ•°æ®")
        
        saver_thread = threading.Thread(target=background_saver, daemon=True)
        saver_thread.start()
        
        # å¼€å§‹åˆ†é¡µå¤„ç†
        page_index = start_page
        previous_companies = []
        
        try:
            while True:
                time.sleep(self.wait_time)
                
                # è·å–å½“å‰é¡µå…¬å¸åˆ—è¡¨
                companies = self.get_companies_page(page_index)
                
                if not companies:
                    print("No response received.", flush=True)
                    break
                
                if not companies or companies == previous_companies:
                    print("No more data available or no new data found. Exiting.", flush=True)
                    break
                
                previous_companies = companies
                print(f"ğŸ“„ å·²è·å–ç¬¬{page_index}é¡µï¼Œå…±{len(companies)}æ¡å‚å±•å•†è®°å½•", flush=True)
                
                # å¤šçº¿ç¨‹å¤„ç†å½“å‰é¡µçš„å…¬å¸
                success_count, total_count = self.process_companies_batch(companies, saved_companies)
                self.processed_count += success_count
                
                print(f"âœ… ç¬¬{page_index}é¡µå¤„ç†å®Œæˆï¼šæˆåŠŸ{success_count}/{total_count}ä¸ªå…¬å¸", flush=True)
                
                # ä¿å­˜è¿›åº¦
                self.progress_manager.save_progress(
                    page_index, 
                    self.data_saver.get_contact_count(), 
                    self.processed_count
                )
                
                page_index += 1
        
        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åºï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...", flush=True)
        
        finally:
            # å¼ºåˆ¶ä¿å­˜æ‰€æœ‰å‰©ä½™æ•°æ®
            print("ğŸ’¾ æ­£åœ¨ä¿å­˜æ‰€æœ‰å‰©ä½™æ•°æ®...", flush=True)
            self.data_saver.force_save_all()
            
            # ä¿å­˜æœ€ç»ˆè¿›åº¦
            self.progress_manager.save_progress(
                page_index, 
                self.data_saver.get_contact_count(), 
                self.processed_count
            )
            
            print(f"\nğŸ‰ æ•°æ®å¤„ç†å®Œæˆï¼", flush=True)
            print(f"=" * 50, flush=True)
            print(f"ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡ï¼š", flush=True)
            print(f"   æ€»å…±è·å–: {self.data_saver.get_contact_count()} ä¸ªè”ç³»äººä¿¡æ¯", flush=True)
            print(f"   å·²ä¿å­˜æ•°: {self.data_saver.get_total_saved()} ä¸ªè”ç³»äºº", flush=True)
            print(f"   å¤„ç†å…¬å¸: {self.processed_count} ä¸ª", flush=True)
            print(f"   å¤„ç†é¡µæ•°: {page_index - start_page + 1} é¡µ", flush=True)
            
            # æ‰“å°è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…æ‹¬é‡è¯•ç»Ÿè®¡ï¼‰
            self.http_client.print_retry_stats()
            
            print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯ï¼š", flush=True)
            print(f"   è¿›åº¦æ–‡ä»¶ï¼š{self.progress_manager.progress_file}", flush=True)
            print(f"   å…¬å¸åˆ—è¡¨ï¼š{self.progress_manager.saved_companies_file}", flush=True)
            print(f"=" * 50, flush=True)


def main():
    """ä¸»å‡½æ•°"""
    global DEBUG_MODE
    
    if len(sys.argv) < 2 or sys.argv[1] in ['--help', '-h', 'help']:
        print("Usage: python common_detail_multithreaded.py <exhibition_code> [options]", flush=True)
        print("Options:", flush=True)
        print("  --reset                é‡ç½®è¿›åº¦ï¼Œä»å¤´å¼€å§‹å¤„ç†", flush=True)
        print("  --debug                å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯", flush=True)
        print("  --page-workers <num>   è®¾ç½®é¡µé¢è·å–çº¿ç¨‹æ•°ï¼ˆé»˜è®¤åŸºäºCPUæ ¸å¿ƒæ•°æ™ºèƒ½è®¾ç½®ï¼‰", flush=True)
        print("  --company-workers <num> è®¾ç½®å…¬å¸å¤„ç†çº¿ç¨‹æ•°ï¼ˆé»˜è®¤åŸºäºCPUæ ¸å¿ƒæ•°æ™ºèƒ½è®¾ç½®ï¼‰", flush=True)
        print("  --help                 æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯", flush=True)
        print("", flush=True)
        print("ç¤ºä¾‹:", flush=True)
        print("  python common_detail_multithreaded.py å†œäº§å“ --page-workers 4 --company-workers 16", flush=True)
        sys.exit(0)
    
    exhibition_code = sys.argv[1]
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    reset_progress = False
    page_workers = None  # ä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼
    company_workers = None  # ä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼
    
    args = sys.argv[2:]
    i = 0
    while i < len(args):
        arg = args[i]
        if arg == "--reset":
            reset_progress = True
        elif arg == "--debug":
            DEBUG_MODE = True
            print("ğŸ” è°ƒè¯•æ¨¡å¼å·²å¼€å¯", flush=True)
        elif arg == "--page-workers" and i + 1 < len(args):
            page_workers = int(args[i + 1])
            i += 1
        elif arg == "--company-workers" and i + 1 < len(args):
            company_workers = int(args[i + 1])
            i += 1
        i += 1
    
    # æ£€æŸ¥æ˜¯å¦è¦é‡ç½®è¿›åº¦
    if reset_progress:
        progress_manager = ThreadSafeProgressManager(exhibition_code)
        progress_manager.reset_progress()
        print("ğŸ”„ è¿›åº¦å·²é‡ç½®ï¼Œå°†ä»å¤´å¼€å§‹å¤„ç†", flush=True)
        return
    
    try:
        # æ„å»ºé…ç½®æ–‡ä»¶è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(script_dir, '..', 'config.detais.xlsx')
        
        print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}", flush=True)
        print(f"å±•è§ˆä»£ç : {exhibition_code}", flush=True)
        
        # æ˜¾ç¤ºCPUæ ¸å¿ƒæ•°å’Œæ™ºèƒ½çº¿ç¨‹é…ç½®
        cpu_count = multiprocessing.cpu_count()
        print(f"ğŸ’» æ£€æµ‹åˆ°CPUæ ¸å¿ƒæ•°: {cpu_count}", flush=True)
        
        # åˆ›å»ºä¸´æ—¶çˆ¬è™«å®ä¾‹ä»¥è·å–å®é™…çº¿ç¨‹æ•°
        temp_crawler = MultiThreadedDataCrawler(exhibition_code, config_path, page_workers, company_workers)
        print(f"âš™ï¸  çº¿ç¨‹é…ç½®ï¼šé¡µé¢è·å–çº¿ç¨‹={temp_crawler.page_workers}, å…¬å¸å¤„ç†çº¿ç¨‹={temp_crawler.company_workers}", flush=True)
        print(f"ğŸ“Š å®é™…æ€»çº¿ç¨‹æ•°: {temp_crawler.page_workers + temp_crawler.company_workers + 1} (å«åå°ä¿å­˜çº¿ç¨‹)", flush=True)
        
        # åˆ›å»ºå¹¶è¿è¡Œå¤šçº¿ç¨‹çˆ¬è™«
        crawler = MultiThreadedDataCrawler(
            exhibition_code, 
            config_path, 
            page_workers=page_workers,
            company_workers=company_workers
        )
        crawler.run()
        
    except Exception as e:
        import traceback
        print(f"An error occurred: {e}", flush=True)
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}", flush=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
